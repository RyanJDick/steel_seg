{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from steel_seg.dataset.severstal_steel_dataset import SeverstalSteelDataset\n",
    "import yaml\n",
    "\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "\n",
    "severstal_test_dir = './data/severstal-steel-defect-detection/test_images/'\n",
    "# with open('SETTINGS.yaml') as f:\n",
    "#     cfg = yaml.load(f)\n",
    "# dataset = SeverstalSteelDataset.init_from_config('SETTINGS.yaml')\n",
    "# val_imgs = dataset.get_image_list('validation')\n",
    "\n",
    "\n",
    "# More feature channels and trained for longer. Threshold tuned by grid search.\n",
    "seg_model_path = './seg_model_20190917-233355.h5' \n",
    "thresh = [0.9, 0.9, 0.9, 0.8]\n",
    "upper_thresh = [0.95, 0.95, 0.95, 0.95]\n",
    "num_px_thresh = [5000, 5000, 5000, 5000]\n",
    "\n",
    "\n",
    "def load_img(img_path):\n",
    "    img = np.array(Image.open(img_path))\n",
    "    img_gray = img[:, :, :1] # All channels are the same\n",
    "    return img_gray\n",
    "\n",
    "def onehottify(x, n=None, dtype=float):\n",
    "    '''1-hot encode x with the max value n (computed from data if n is None).\n",
    "    '''\n",
    "    x = np.asarray(x)\n",
    "    n = np.max(x) + 1 if n is None else n\n",
    "    return np.eye(n, dtype=dtype)[x]\n",
    "\n",
    "def postprocess(y, thresh=None, upper_thresh=None, num_px_thresh=None):\n",
    "    if thresh is None:\n",
    "        thresh = [0.85, 0.85, 0.85, 0.85]\n",
    "    if upper_thresh is None:\n",
    "        upper_thresh = [0.85, 0.85, 0.85, 0.85]\n",
    "    if num_px_thresh is None:\n",
    "        num_px_thresh = [5000, 5000, 5000, 5000]\n",
    "    # TODO: handle batches properly\n",
    "    batches, height, width, classes = y.shape\n",
    "    assert batches == 1\n",
    "    \n",
    "    # Only allow one class at each pixel\n",
    "    y_argmax = np.argmax(y, axis=-1)\n",
    "    y_one_hot = onehottify(y_argmax, y.shape[-1], dtype=int)\n",
    "    for c in range(classes):\n",
    "        y_one_hot[:, :, :, c][y[:, :, :, c] < thresh[c]] = 0 # Background\n",
    "    \n",
    "    # Making predictions on an empty mask is very costly (score immediately goes from 1 to 0)\n",
    "    # So, only predict a mask if there are many pixels (num_px_thresh) above a high threshold (upper_thresh)\n",
    "    for c in range(classes):\n",
    "        pixels_above_upper = np.sum(y[:, :, :, c] > upper_thresh[c])\n",
    "        if pixels_above_upper < num_px_thresh[c]:\n",
    "            y_one_hot[:, :, :, c] = 0\n",
    "    return y_one_hot\n",
    "\n",
    "def dense_to_rle(dense):\n",
    "    '''Convert the dense np ndarray representation of a single class mask to the equivalent rle\n",
    "    representation.\n",
    "    '''\n",
    "    assert len(dense.shape) == 2\n",
    "    # Use Fortran (column-major) ordering\n",
    "    pixels = dense.flatten(order='F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def store_preds(y_one_hot, img_name, preds):\n",
    "    for c in range(y_one_hot.shape[-1]):\n",
    "        preds.append(f'{img_name}_{c+1},{dense_to_rle(y_one_hot[0, :, :, c])}')\n",
    "\n",
    "\n",
    "# Load model\n",
    "seg_model = tf.keras.models.load_model(seg_model_path)\n",
    "\n",
    "# Make preds\n",
    "preds = []\n",
    "preds.append('ImageId_ClassId,EncodedPixels')\n",
    "#val_imgs.sort()\n",
    "img_names = os.listdir(severstal_test_dir)\n",
    "img_names.sort()\n",
    "for i, img_name in enumerate(img_names):\n",
    "    if i % 100 == 0:\n",
    "        print(f'Running inference on image {i} / {len(img_names)}')\n",
    "    img_path = os.path.join(severstal_test_dir, img_name)\n",
    "    img = load_img(img_path)\n",
    "    img_batch = np.expand_dims(img, axis=0)\n",
    "\n",
    "    y = seg_model.predict(img_batch)\n",
    "    y_one_hot = postprocess(y, thresh, upper_thresh, num_px_thresh)\n",
    "    \n",
    "    store_preds(y_one_hot, img_name, preds)\n",
    "\n",
    "# Save to file\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.writelines([p + '\\n' for p in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
