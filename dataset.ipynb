{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good reference: https://www.tensorflow.org/guide/performance/datasets\n",
    "# Another good reference: https://www.tensorflow.org/guide/datasets\n",
    "# Might be able to store all data in memory, but will implement at first as though this is not an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from dataset.severstal_steel_dataset import load_annotations, rle_to_dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_DIR = './severstal-steel-defect-detection/train_images/'\n",
    "TRAIN_ANNOTATIONS_FILE = './severstal-steel-defect-detection/train.csv'\n",
    "TFRECORD_DIR = 'severstal_steel_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = load_annotations(TRAIN_ANNOTATIONS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "os.makedirs(TFRECORD_DIR, exist_ok=True)\n",
    "\n",
    "anns_list = list(anns.items())\n",
    "examples_per_file = 2000\n",
    "batch_start = 0\n",
    "file_index = 0\n",
    "while batch_start < len(anns_list):\n",
    "    batch_end = min(batch_start + examples_per_file, len(anns_list))\n",
    "    print(f'Starting batch {batch_start}-{batch_end} out of {len(anns_list)}')\n",
    "    with tf.python_io.TFRecordWriter(os.path.join(TFRECORD_DIR, f'severstal_steel_{file_index}.tfrecord')) as writer:\n",
    "        for i in range(batch_start, batch_end):\n",
    "            img_name, annotations_dict = anns_list[i]\n",
    "\n",
    "            # Load image\n",
    "            img_path = os.path.join(TRAIN_IMAGE_DIR, img_name)\n",
    "            img = np.array(Image.open(img_path))\n",
    "            img_gray = img[:, :, 0] # All channels are the same\n",
    "\n",
    "            # Load annotations\n",
    "            dense_anns = []\n",
    "            for cls in ['1', '2', '3', '4']:\n",
    "                dense_ann = rle_to_dense(annotations_dict[cls], img_gray.shape[0], img_gray.shape[1])\n",
    "                dense_anns.append(dense_ann)\n",
    "            annotation_array = np.stack(dense_anns, axis=-1)\n",
    "            annotation_array.astype(np.uint8)\n",
    "\n",
    "            # Serialize example\n",
    "            assert img_gray.dtype == np.uint8\n",
    "            assert annotation_array.dtype == np.uint8\n",
    "            feature = {\n",
    "                'image':       _bytes_feature(tf.compat.as_bytes(img_gray.tostring())),\n",
    "                'annotations': _bytes_feature(tf.compat.as_bytes(annotation_array.tostring()))\n",
    "            }\n",
    "            example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "            # Write to TFRecord file\n",
    "            writer.write(example_proto.SerializeToString())\n",
    "    batch_start = batch_end\n",
    "    file_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(anns_file, out_dir):\n",
    "    anns = load_annotations(TRAIN_ANNOTATIONS_FILE)\n",
    "    for img_filename, annotations_dict in anns.items():\n",
    "        img_id, _ = os.path.splitext(img_filename)\n",
    "        out_file = os.path.join(out_dir, f'{img_id}.npz')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "anns = load_annotations(TRAIN_ANNOTATIONS_FILE)\n",
    "\n",
    "\n",
    "# create filewriter\n",
    "writer = tf.python_io.TFRecordWriter(FILEPATH)\n",
    "\n",
    "\n",
    "# Define the features of your tfrecord\n",
    "feature = {'image':  _bytes_feature(tf.compat.as_bytes(image.tostring())),\n",
    "           'label':  _int64_feature(int(label))}\n",
    "\n",
    "\n",
    "# Serialize to string and write to file\n",
    "example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "writer.write(example.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
