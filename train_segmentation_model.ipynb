{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a UNet segmentation model on the Severstal steel defect dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from steel_seg.utils import dice_coeff_kaggle, rle_to_dense, dense_to_rle, visualize_segmentations\n",
    "from steel_seg.dataset.severstal_steel_dataset import SeverstalSteelDataset\n",
    "from steel_seg.model.unet import build_unet_model\n",
    "from steel_seg.model.deep_q_postprocessor import build_deep_q_model\n",
    "from steel_seg.train import class_weighted_binary_crossentropy, weighted_binary_crossentropy, dice_coef, eval, empty_mask_loss, empty_mask_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary for CUDA 10 or something?\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = \"1\"\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_GRAPH_REWRITE\"] = \"1\"\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_LOSS_SCALING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SETTINGS.yaml') as f:\n",
    "    cfg = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SeverstalSteelDataset.init_from_config('SETTINGS.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_batches = dataset.create_dataset(dataset_type='training')\n",
    "val_data, val_batches = dataset.create_dataset(dataset_type='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = build_unet_model(\n",
    "    img_height=cfg['IMG_HEIGHT'],\n",
    "    img_width=cfg['IMG_WIDTH'],\n",
    "    img_channels=1,\n",
    "    num_classes=cfg['NUM_CLASSES'],\n",
    "    num_layers=4,\n",
    "    activation=tf.keras.activations.elu,\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_size=(3, 3),\n",
    "    pool_size=(2, 4),\n",
    "    num_features=[8, 16, 32, 64],\n",
    "    drop_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs = dataset.get_image_list('training')\n",
    "\n",
    "# cls_pixel_counts = [0, 0, 0, 0]\n",
    "# for img_name in train_imgs:\n",
    "#     img, ann = dataset.get_example_from_img_name(img_name)\n",
    "#     for i in range(ann.shape[-1]):\n",
    "#         cls_pixel_counts[i] += np.sum(ann[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_2_weight = 10.0\n",
    "# cls_0_weight = (cls_pixel_counts[2] * cls_2_weight) / cls_pixel_counts[0]\n",
    "# cls_1_weight = (cls_pixel_counts[2] * cls_2_weight) / cls_pixel_counts[1]\n",
    "# cls_3_weight = (cls_pixel_counts[2] * cls_2_weight) / cls_pixel_counts[3]\n",
    "# cls_weights = [cls_0_weight, cls_1_weight, cls_2_weight, cls_3_weight]\n",
    "#cls_weights = [332.7316460371491, 1661.6470474376874, 10.0, 47.50019711767978]\n",
    "cls_weights = [30.0, 40.0, 10.0, 20.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(0.0005),\n",
    "    loss=class_weighted_binary_crossentropy(cls_weights),#weighted_binary_crossentropy(10.0),#'binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(), dice_coef(batch_size=cfg['BATCH_SIZE'])])#[dice_coef, 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "#model.load_weights('checkpoints/cp_20190814-224021.ckpt')\n",
    "seg_model.load_weights('checkpoints/cp_20190820-085420.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f'checkpoints/cp_{date_str}.ckpt'\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_weights_only=True, verbose=1)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=8, monitor='val_loss')\n",
    "\n",
    "logdir = \"logs/\" + date_str\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "    checkpoint_cb,\n",
    "    early_stopping_cb,\n",
    "]\n",
    "\n",
    "results = seg_model.fit(train_data,\n",
    "                    epochs=200,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_data,\n",
    "                    steps_per_epoch=train_batches,\n",
    "                    validation_steps=val_batches,\n",
    "                    validation_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs = dataset.get_image_list('validation')\n",
    "len(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move these functions out to .py files\n",
    "\n",
    "def onehottify(x, n=None, dtype=float):\n",
    "    '''1-hot encode x with the max value n (computed from data if n is None).\n",
    "    '''\n",
    "    x = np.asarray(x)\n",
    "    n = np.max(x) + 1 if n is None else n\n",
    "    return np.eye(n, dtype=dtype)[x]\n",
    "# postprocess(y, thresh=0.8, upper_thresh=0.8, num_px_thresh=10000): 0.8795549804140013\n",
    "# postprocess(y, thresh=0.7, upper_thresh=0.7, num_px_thresh=10000): 0.8685514979767833\n",
    "# postprocess(y, thresh=0.8, upper_thresh=0.8, num_px_thresh=20000): 0.8597784574292987\n",
    "# postprocess(y, thresh=0.8, upper_thresh=0.8, num_px_thresh=5000):  0.888272717085689\n",
    "# postprocess(y, thresh=0.85, upper_thresh=0.85, num_px_thresh=5000): 0.8933982786371334\n",
    "# postprocess(y, thresh=0.85, upper_thresh=0.85, num_px_thresh=2000): 0.8862070712564566\n",
    "# postprocess(y, thresh=0.9, upper_thresh=0.9, num_px_thresh=2000):  0.8899766923286324\n",
    "\n",
    "def postprocess(y, thresh=0.85, upper_thresh=0.85, num_px_thresh=5000):\n",
    "    # TODO: handle batches properly\n",
    "    \n",
    "    # Making predictions on an empty mask is very costly (score immediately goes from 1 to 0)\n",
    "    # So, only predict a mask if there are many pixels (num_px_thresh) above a high threshold (upper_thresh)\n",
    "    y_post = np.zeros_like(y)\n",
    "    for c in range(y.shape[-1]):\n",
    "        pixels_above_upper = np.sum(y[:, :, :, c] > upper_thresh)\n",
    "        if pixels_above_upper > num_px_thresh:\n",
    "            y_post[:, :, :, c] = y[:, :, :, c]\n",
    "    \n",
    "    # Only allow one class at each pixel\n",
    "    y_argmax = np.argmax(y_post, axis=-1)\n",
    "    y_one_hot = onehottify(y_argmax, y.shape[-1])\n",
    "    y_one_hot[y < thresh] = 0\n",
    "    return y_one_hot\n",
    "\n",
    "def eval(model, dataset, img_list):\n",
    "    dice_coeffs = []\n",
    "    for img_name in img_list:\n",
    "        img, ann = dataset.get_example_from_img_name(img_name)\n",
    "        img_batch = np.expand_dims(img, axis=0)\n",
    "        y = model.predict(img_batch)\n",
    "        y_one_hot = postprocess(y)\n",
    "        dice_coeffs.append(dice_coeff_kaggle(y_one_hot[0, :, :, :], ann))\n",
    "    mean_dice_coeff = np.mean(dice_coeffs)\n",
    "    print(f'Mean dice coeff: {mean_dice_coeff}')\n",
    "    return mean_dice_coeff, dice_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice_coeff, dice_coeffs = eval(model, dataset, val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(dice_coeffs)[:50] # Indices of 10 worst images\n",
    "for i in indices:\n",
    "    print(f'{i}: {dice_coeffs[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Image Prediction\n",
    "img_id = 101\n",
    "thresh = 0.85\n",
    "\n",
    "img_name = val_imgs[img_id]\n",
    "img, ann = dataset.get_example_from_img_name(img_name)\n",
    "img_batch = np.expand_dims(img, axis=0)\n",
    "y = seg_model.predict(img_batch)\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(visualize_segmentations(np.repeat(img, 3, axis=-1), ann))\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 0] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 1] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 2] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 3] > thresh)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
