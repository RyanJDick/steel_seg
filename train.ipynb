{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from steel_seg.dataset.severstal_steel_dataset import SeverstalSteelDataset, visualize_segmentations, dense_to_rle, rle_to_dense\n",
    "from steel_seg.dataset.deep_q_data_generator import DeepQDataGenerator\n",
    "from steel_seg.model.unet import build_unet_model\n",
    "from steel_seg.model.deep_q_postprocessor import build_deep_q_model\n",
    "from steel_seg.train import class_weighted_binary_crossentropy, dice_coef, dice_coeff_kaggle, eval\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Figure out how to submit model\n",
    "# Alternative loss functions?\n",
    "#    - Weight boundary pixels more heavily\n",
    "#    - Are class weights necessary?\n",
    "#    - BCE + dice loss\n",
    "#    - Jacquard? Others?\n",
    "#    - Focal loss?\n",
    "# Further post-processing\n",
    "#    - Identify segments, and process them 1-by-1\n",
    "#    - Different thresholds for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary for CUDA 10 or something?\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = \"1\"\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_GRAPH_REWRITE\"] = \"1\"\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_LOSS_SCALING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To run in half-precision mode on GPU\n",
    "# dtype='float16'\n",
    "# K.set_floatx(dtype)\n",
    "\n",
    "# # default is 1e-7 which is too small for float16.  Without adjusting the epsilon, we will get NaN predictions because of divide by zero problems\n",
    "# K.set_epsilon(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SeverstalSteelDataset.init_from_config('SETTINGS.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_batches = dataset.create_dataset(dataset_type='training')\n",
    "val_data, val_batches = dataset.create_dataset(dataset_type='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SETTINGS.yaml') as f:\n",
    "    cfg = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet_model(\n",
    "    img_height=cfg['IMG_HEIGHT'],\n",
    "    img_width=cfg['IMG_WIDTH'],\n",
    "    img_channels=1,\n",
    "    num_classes=cfg['NUM_CLASSES'],\n",
    "    num_layers=4,\n",
    "    activation=tf.keras.activations.elu,\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_size=(3, 3),\n",
    "    pool_size=(2, 4),\n",
    "    num_features=[8, 16, 32, 64],\n",
    "    drop_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imgs = dataset.get_image_list('training')\n",
    "\n",
    "# cls_pixel_counts = [0, 0, 0, 0]\n",
    "# for img_name in train_imgs:\n",
    "#     img, ann = dataset.get_example_from_img_name(img_name)\n",
    "#     for i in range(ann.shape[-1]):\n",
    "#         cls_pixel_counts[i] += np.sum(ann[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_2_weight = 10.0\n",
    "# cls_0_weight = (cls_pixel_counts[2] * cls_2_weight) / cls_pixel_counts[0]\n",
    "# cls_1_weight = (cls_pixel_counts[2] * cls_2_weight) / cls_pixel_counts[1]\n",
    "# cls_3_weight = (cls_pixel_counts[2] * cls_2_weight) / cls_pixel_counts[3]\n",
    "# cls_weights = [cls_0_weight, cls_1_weight, cls_2_weight, cls_3_weight]\n",
    "#cls_weights = [332.7316460371491, 1661.6470474376874, 10.0, 47.50019711767978]\n",
    "cls_weights = [30.0, 40.0, 10.0, 20.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0005),\n",
    "              loss=class_weighted_binary_crossentropy(cls_weights),#weighted_binary_crossentropy(10.0),#'binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(), dice_coef(batch_size=cfg['BATCH_SIZE'])])#[dice_coef, 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from checkpoint\n",
    "#model.load_weights('checkpoints/cp_20190814-224021.ckpt')\n",
    "model.load_weights('checkpoints/cp_20190820-085420.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f'checkpoints/cp_{date_str}.ckpt'\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_weights_only=True, verbose=1)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=8, monitor='val_loss')\n",
    "\n",
    "logdir = \"logs/\" + date_str\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "    checkpoint_cb,\n",
    "    early_stopping_cb,\n",
    "]\n",
    "\n",
    "results = model.fit(train_data,\n",
    "                    epochs=200,\n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_data,\n",
    "                    steps_per_epoch=train_batches,\n",
    "                    validation_steps=val_batches,\n",
    "                    validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs = dataset.get_image_list('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehottify(x, n=None, dtype=float):\n",
    "    '''1-hot encode x with the max value n (computed from data if n is None).\n",
    "    '''\n",
    "    x = np.asarray(x)\n",
    "    n = np.max(x) + 1 if n is None else n\n",
    "    return np.eye(n, dtype=dtype)[x]\n",
    "# postprocess(y, thresh=0.8, upper_thresh=0.8, num_px_thresh=10000): 0.8795549804140013\n",
    "# postprocess(y, thresh=0.7, upper_thresh=0.7, num_px_thresh=10000): 0.8685514979767833\n",
    "# postprocess(y, thresh=0.8, upper_thresh=0.8, num_px_thresh=20000): 0.8597784574292987\n",
    "# postprocess(y, thresh=0.8, upper_thresh=0.8, num_px_thresh=5000):  0.888272717085689\n",
    "# postprocess(y, thresh=0.85, upper_thresh=0.85, num_px_thresh=5000): 0.8933982786371334\n",
    "# postprocess(y, thresh=0.85, upper_thresh=0.85, num_px_thresh=2000): 0.8862070712564566\n",
    "# postprocess(y, thresh=0.9, upper_thresh=0.9, num_px_thresh=2000):  0.8899766923286324\n",
    "\n",
    "def postprocess(y, thresh=0.85, upper_thresh=0.85, num_px_thresh=5000):\n",
    "    # TODO: handle batches properly\n",
    "    \n",
    "    # Making predictions on an empty mask is very costly (score immediately goes from 1 to 0)\n",
    "    # So, only predict a mask if there are many pixels (num_px_thresh) above a high threshold (upper_thresh)\n",
    "    y_post = np.zeros_like(y)\n",
    "    for c in range(y.shape[-1]):\n",
    "        pixels_above_upper = np.sum(y[:, :, :, c] > upper_thresh)\n",
    "        if pixels_above_upper > num_px_thresh:\n",
    "            y_post[:, :, :, c] = y[:, :, :, c]\n",
    "    \n",
    "    # Only allow one class at each pixel\n",
    "    y_argmax = np.argmax(y_post, axis=-1)\n",
    "    y_one_hot = onehottify(y_argmax, y.shape[-1])\n",
    "    y_one_hot[y < thresh] = 0\n",
    "    return y_one_hot\n",
    "\n",
    "def eval(model, dataset, img_list):\n",
    "    dice_coeffs = []\n",
    "    for img_name in img_list:\n",
    "        img, ann = dataset.get_example_from_img_name(img_name)\n",
    "        img_batch = np.expand_dims(img, axis=0)\n",
    "        y = model.predict(img_batch)\n",
    "        y_one_hot = postprocess(y)\n",
    "        dice_coeffs.append(dice_coeff_kaggle(y_one_hot[0, :, :, :], ann))\n",
    "    mean_dice_coeff = np.mean(dice_coeffs)\n",
    "    print(f'Mean dice coeff: {mean_dice_coeff}')\n",
    "    return mean_dice_coeff, dice_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice_coeff, dice_coeffs = eval(model, dataset, val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(dice_coeffs)[:50] # Indices of 10 worst images\n",
    "for i in indices:\n",
    "    print(f'{i}: {dice_coeffs[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = val_imgs[101]\n",
    "img, ann = dataset.get_example_from_img_name(img_name)\n",
    "img_batch = np.expand_dims(img, axis=0)\n",
    "y = model.predict(img_batch)\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(visualize_segmentations(np.repeat(img, 3, axis=-1), ann))\n",
    "plt.show()\n",
    "thresh = 0.9\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 0] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 1] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 2] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 3] > thresh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Post-Processing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_model = build_deep_q_model(\n",
    "    img_height=cfg['IMG_HEIGHT'],\n",
    "    img_width=cfg['IMG_WIDTH'],\n",
    "    num_classes=cfg['NUM_CLASSES'],\n",
    "    num_layers=4,\n",
    "    activation=tf.keras.activations.elu,\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_size=(3, 3),\n",
    "    pool_size=(2, 4),\n",
    "    num_features=[4, 4, 4, 4],\n",
    "    drop_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.losses.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steel_seg.dataset.deep_q_data_generator import DeepQDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = DeepQDataGenerator(\n",
    "    base_model=model,\n",
    "    steel_dataset=dataset,\n",
    "    dataset_name='training',\n",
    "    batch_size=cfg['BATCH_SIZE'],\n",
    "    threshold=0.85,\n",
    "    img_height=cfg['IMG_HEIGHT'],\n",
    "    img_width=cfg['IMG_WIDTH'],\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_generator = DeepQDataGenerator(\n",
    "    base_model=model,\n",
    "    steel_dataset=dataset,\n",
    "    dataset_name='validation',\n",
    "    batch_size=cfg['BATCH_SIZE'],\n",
    "    threshold=0.85,\n",
    "    img_height=cfg['IMG_HEIGHT'],\n",
    "    img_width=cfg['IMG_WIDTH'],\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp_20190828-225036.ckpt\n",
    "#cp_20190829-222109.ckpt\n",
    "#cp_20190829-225130.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = f'postprocess_checkpoints/cp_{date_str}.ckpt'\n",
    "\n",
    "# Create checkpoint callback\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_weights_only=True, verbose=1)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=8, monitor='val_loss')\n",
    "\n",
    "logdir = \"postprocessing_logs/\" + date_str\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=logdir),\n",
    "    checkpoint_cb,\n",
    "    early_stopping_cb,\n",
    "]\n",
    "\n",
    "results = post_model.fit(train_data_generator,\n",
    "                         epochs=200,\n",
    "                         verbose=2,\n",
    "                         callbacks=callbacks,\n",
    "                         validation_data=val_data_generator,\n",
    "                         steps_per_epoch=len(train_data_generator),\n",
    "                         validation_steps=len(val_data_generator),\n",
    "                         validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs = dataset.get_image_list('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steel_seg.dataset.deep_q_data_generator import postprocess\n",
    "def deep_q_postprocess(y, post_model):\n",
    "    pred_scores = post_model.predict(y)\n",
    "    #print(pred_scores)\n",
    "    y_post = np.copy(y)\n",
    "    for batch in range(y_post.shape[0]):\n",
    "        for cls in range(y_post.shape[-1]):\n",
    "            # If no_mask_score > mask_score\n",
    "            if pred_scores[batch, cls, 1] > pred_scores[batch, cls, 0]:\n",
    "                y_post[batch, :, :, cls] = 0\n",
    "    return y_post\n",
    "\n",
    "def eval(model, post_model, dataset, img_list):\n",
    "    dice_coeffs = []\n",
    "    for img_name in img_list:\n",
    "        img, ann = dataset.get_example_from_img_name(img_name)\n",
    "        img_batch = np.expand_dims(img, axis=0)\n",
    "        y = model.predict(img_batch)\n",
    "        y_one_hot = postprocess(y, 0.85) #TODO: ad thresh to config file\n",
    "        y_post = deep_q_postprocess(y_one_hot, post_model)\n",
    "        dice_coeffs.append(dice_coeff_kaggle(y_post[0, :, :, :], ann))\n",
    "    mean_dice_coeff = np.mean(dice_coeffs)\n",
    "    print(f'Mean dice coeff: {mean_dice_coeff}')\n",
    "    return mean_dice_coeff, dice_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice_coeff, dice_coeffs = eval(model, post_model, dataset, val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(dice_coeffs)[:50] # Indices of 10 worst images\n",
    "for i in indices:\n",
    "    print(f'{i}: {dice_coeffs[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = val_imgs[903]\n",
    "img, ann = dataset.get_example_from_img_name(img_name)\n",
    "img_batch = np.expand_dims(img, axis=0)\n",
    "y = model.predict(img_batch)\n",
    "y_one_hot = postprocess(y, 0.85) #TODO: ad thresh to config file\n",
    "y_post = deep_q_postprocess(y_one_hot, post_model)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(visualize_segmentations(np.repeat(img, 3, axis=-1), ann))\n",
    "plt.show()\n",
    "thresh = 0.85\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 0] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 1] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 2] > thresh)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y[0, :, :, 3] > thresh)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y_post[0, :, :, 0])\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y_post[0, :, :, 1])\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y_post[0, :, :, 2])\n",
    "plt.show()\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.imshow(y_post[0, :, :, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
